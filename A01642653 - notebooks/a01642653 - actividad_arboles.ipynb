{"cells":[{"cell_type":"markdown","id":"e0a0365e","metadata":{"id":"e0a0365e"},"source":["## Actividad √°rboles y bosques\n","\n","En esta pr√°ctica aprender√°s a:\n","- Entrenar y afinar un √Årbol de Decisi√≥n.\n","- Construir un bosque manual de √°rboles y combinar sus predicciones mediante voto mayoritario.\n","- Observar c√≥mo un ensamble de modelos puede superar a un solo √°rbol."]},{"cell_type":"markdown","id":"97f5e7bb","metadata":{"id":"97f5e7bb"},"source":["#### Parte 1"]},{"cell_type":"markdown","id":"9171ba00","metadata":{"id":"9171ba00"},"source":["1. Generar datos\n","    - Crea un dataset en forma de lunas con:\n","    - make_moons(n_samples=10000, noise=0.4)\n","\n","2. Dividir los datos\n","    - Separa en conjunto de entrenamiento y de prueba usando train_test_split().\n","\n","3. Ajustar el modelo\n","    - Usa b√∫squeda en malla (grid search) con validaci√≥n cruzada (clase GridSearchCV) para encontrar buenos hiperpar√°metros para un DecisionTreeClassifier.\n","    - Pista: prueba distintos valores de max_leaf_nodes.\n","\n","4. Entrenar y evaluar\n","    - Entrena el √°rbol con todo el conjunto de entrenamiento usando los hiperpar√°metros √≥ptimos.\n","    - Eval√∫a en el conjunto de prueba.\n","\n","Deber√≠as obtener aproximadamente 85%‚Äì87% de precisi√≥n."]},{"cell_type":"code","execution_count":1,"id":"7ff68ccd","metadata":{"id":"7ff68ccd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756428212476,"user_tz":360,"elapsed":33168,"user":{"displayName":"Cristobal CamHer","userId":"07487221864848747057"}},"outputId":"bebf7c81-ac0b-4503-d4f4-964ba4f9cd34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mejores hiperpar√°metros: {'max_leaf_nodes': 23}\n","Precisi√≥n en el conjunto de prueba: 0.8735\n"]}],"source":["from sklearn.datasets import make_moons\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","param_grid = {'max_leaf_nodes': range(2, 100)}\n","tree_clf = DecisionTreeClassifier(random_state=42)\n","grid_search = GridSearchCV(tree_clf, param_grid, cv=5)\n","grid_search.fit(X_train, y_train)\n","\n","best_tree_clf = grid_search.best_estimator_\n","\n","best_tree_clf.fit(X_train, y_train)\n","y_pred = best_tree_clf.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print(f\"Mejores hiperpar√°metros: {grid_search.best_params_}\")\n","print(f\"Precisi√≥n en el conjunto de prueba: {accuracy:.4f}\")"]},{"cell_type":"markdown","id":"56a48d04","metadata":{"id":"56a48d04"},"source":["#### Parte 2 Crecer un bosque\n"]},{"cell_type":"markdown","id":"b3729eb6","metadata":{"id":"b3729eb6"},"source":["\n","1. Generar subconjuntos\n","    - Crea 1,000 subconjuntos del conjunto de entrenamiento, cada uno con 100 instancias seleccionadas aleatoriamente.\n","    - Pista: usa ShuffleSplit de Scikit-Learn.\n","\n","2. Entrenar m√∫ltiples √°rboles\n","    - Entrena un DecisionTreeClassifier en cada subconjunto, usando los mejores hiperpar√°metros encontrados en la Parte 1.\n","    - Eval√∫a cada √°rbol individual en el conjunto de prueba.\n","    - Como fueron entrenados en conjuntos peque√±os, se espera que tengan solo ‚âà80% de precisi√≥n.\n","\n","3. Combinar predicciones\n","    - Para cada instancia del conjunto de prueba, recolecta las predicciones de los 1,000 √°rboles.\n","    - Conservar √∫nicamente la predicci√≥n m√°s frecuente usando mode() de SciPy.\n","    - Esto implementa un voto mayoritario.\n","\n","4. Evaluar el bosque\n","    - Eval√∫a las predicciones combinadas en el conjunto de prueba.\n","    - Deber√≠as obtener una precisi√≥n ligeramente mayor que la del √°rbol individual (+0.5% a +1.5%).\n","\n","üéâ ¬°Felicidades, has implementado tu propio Random Forest desde cero!"]},{"cell_type":"code","execution_count":3,"id":"c15c3d34","metadata":{"id":"c15c3d34","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756428313723,"user_tz":360,"elapsed":3053,"user":{"displayName":"Cristobal CamHer","userId":"07487221864848747057"}},"outputId":"c1162a35-89ec-4806-94e1-6cac08c6341b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Precisi√≥n promedio de los √°rboles individuales: 0.7988\n","Precisi√≥n del bosque: 0.8735\n"]}],"source":["from sklearn.model_selection import ShuffleSplit\n","from scipy.stats import mode\n","import numpy as np\n","\n","n_trees = 1000\n","n_instances = 100\n","shuffle_split = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)\n","\n","trees = []\n","accuracy_scores = []\n","\n","for train_index, test_index in shuffle_split.split(X_train):\n","    X_subset = X_train[train_index]\n","    y_subset = y_train[train_index]\n","\n","    tree_clf = DecisionTreeClassifier(max_leaf_nodes=grid_search.best_params_['max_leaf_nodes'], random_state=42)\n","    tree_clf.fit(X_subset, y_subset)\n","    trees.append(tree_clf)\n","\n","    y_pred_individual = tree_clf.predict(X_test)\n","    accuracy_scores.append(accuracy_score(y_test, y_pred_individual))\n","\n","print(f\"Precisi√≥n promedio de los √°rboles individuales: {np.mean(accuracy_scores):.4f}\")\n","\n","y_pred_ensemble = np.empty([len(X_test), n_trees], dtype=np.int64)\n","\n","for i, tree in enumerate(trees):\n","    y_pred_ensemble[:, i] = tree.predict(X_test)\n","\n","y_pred_forest, _ = mode(y_pred_ensemble, axis=1)\n","\n","accuracy_forest = accuracy_score(y_test, y_pred_forest)\n","print(f\"Precisi√≥n del bosque: {accuracy_forest:.4f}\")"]}],"metadata":{"kernelspec":{"display_name":"ds","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"colab":{"provenance":[{"file_id":"https://github.com/noe-tec/machine-learning/blob/main/notebooks/actividad_arboles.ipynb","timestamp":1756428147688}]}},"nbformat":4,"nbformat_minor":5}